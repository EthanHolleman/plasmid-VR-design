{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "00c23a83c2b46508eab46721384ef0dc3f4ee71e161598ca59ff0b5caf782b8e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Putting different metrics of sequence quality on comparible scales\n",
    "\n",
    "For each sequence generated we want to be able to compare multible metrics to rank sequences and select the best one.\n",
    "However, each metric may have a different meaning. A high value may be desireable in one case but not in another.\n",
    "\n",
    "In each case there needs to be some kind of expectation. Currently expectations are formed by generating random\n",
    "sequences, measuring the metric of interest for each sequence and using the mean value as the expectation. With\n",
    "this approach the degree to which a generated sequence differs from the expectation can be measured in\n",
    "standard deviations by converting the value of the metric to a z score. This leaves us with the problem\n",
    "above. It would be good to get all metrics on some more absolute scale where a specific direction (high or low\n",
    "values is always desireable) for easier comparisons.\n",
    "\n",
    "## Metric classes\n",
    "\n",
    "The desired value for a given metric can be defined with two goals; you either want to maximize or minimize\n",
    "the distance (in standard deviations) to the mean and you either want that value to be positive or negative\n",
    "(greater or less than the mean).\n",
    "\n",
    "Going forward, we want to produce a scale where large numbers always represent more desireable values.\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "example_mean = 10\n",
    "example_samples = np.array([-2, -5, 4, -3, 1])  # distance to mean in sd\n"
   ]
  },
  {
   "source": [
    "### Positive or negative\n",
    "\n",
    "Multiply the metric value by 1 if desired value is + or by `-1` if -.\n",
    "In this example lets say the desired result is to the right of the mean."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-2, -5,  4, -3,  1])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "direction = 1\n",
    "dir_samples = example_samples * direction\n",
    "dir_samples"
   ]
  },
  {
   "source": [
    "### Max or min\n",
    "\n",
    "If distance from mean should be maximized do nothing to values, if minimized take reciprocol.\n",
    "\n",
    "In this case we want to minimize value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.5       , -0.2       ,  0.25      , -0.33333333,  1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "min_max = lambda x: 1 / x\n",
    "dir_min_samples = np.vectorize(min_max)(dir_samples)\n",
    "dir_min_samples\n"
   ]
  },
  {
   "source": [
    "Then can just sort"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.5       , -0.33333333, -0.2       ,  0.25      ,  1.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "np.sort(dir_min_samples)"
   ]
  },
  {
   "source": [
    "1 is to the right of mean and closest to it (on the right.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Debugging\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 10\n",
    "sd = 1\n",
    "z_score = lambda x: (x - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{12: 2.0, 3: -7.0, 10.1: 0.09999999999999964, 7: -3.0, 14: 4.0, 8: -2.0}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "vals = 12, 3, 10.1, 7, 14, 8\n",
    "raw_scores = {val: z_score(val) for val in vals}\n",
    "raw_scores"
   ]
  },
  {
   "source": [
    "### Want to max distance to the mean\n",
    "\n",
    "So we want the largest z score (multply by one)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Min distance to mean\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{12: 0.5,\n",
       " 3: -0.14285714285714285,\n",
       " 10.1: 10.000000000000036,\n",
       " 7: -0.3333333333333333,\n",
       " 14: 0.25,\n",
       " 8: -0.5}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "min_scores = {val: z ** -1 for val, z in raw_scores.items()}\n",
    "min_scores\n"
   ]
  },
  {
   "source": [
    "1/x will not work because does not grow / shrink in a linear way. Instead can use a ranking approach and then only really consider values that\n",
    "fall on the desired half of the distrabution."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_max_z_score(scores):\n",
    "    # rank scores in order to maximize distance from mean\n",
    "    scores = sorted(scores, lambda s: abs(s), reverse=True)  # sort by absolute value\n",
    "    return scores\n",
    "\n",
    "def rank_min_z_scores(scores):\n",
    "    # rank to minimize absolute distance from mean\n",
    "    scores sorted(scores, lambda s: abs(s))\n",
    "    return scores"
   ]
  },
  {
   "source": [
    "Just throw out values not in the desired direction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_scores(scores, direction, divergence):\n",
    "    if direction == 1:\n",
    "        temp_scores = [s for s in scores if s > 0]\n",
    "    else:\n",
    "        temp_scores = [s for s in scores if s < 0]\n",
    "    \n",
    "    if divergence == 1:  # max distance to mean\n",
    "        temp_scores = sorted(temp_scores, key=lambda s: abs(s), reverse=True)\n",
    "    else:\n",
    "        temp_scores = sorted(temp_scores, key=lambda s: abs(s))\n",
    "    \n",
    "    # collect all scores that were dropped\n",
    "    dropped_scores = set(scores) - set(temp_scores)\n",
    "    "
   ]
  }
 ]
}